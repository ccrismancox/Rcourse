values_to = 'press'  ) %>% ##What to call column with the data
mutate(year  = as.numeric(year))
library(tidyr) # tidy pivoting functions
##Freedom House data on Freedom of the Press
pressData <- read_csv('Datasets/Press_FH.csv')
##It has  a column for country names and then a bunch of years
##We want to reshape it into a country year format
colnames(pressData)
pressData <- pressData %>%
pivot_longer(cols = !country, #colnames to swing around (everything but country)
names_to ='year', ##What to call column that is
# now the old column names
names_prefix = "X", #removeing prefix
values_to = 'press'  ) %>% ##What to call column with the data
mutate(year  = as.numeric(year))
head(pressData)
?pivot_wider
###Creates and attaches the new variable to the data frame
#base way
FL2003$lgdp <- log(FL2003$lgdpen)
#tidy
FL2003 <- FL2003 %>%
mutate(lgdp = log(lgdpen))
#tidy
FL2003 <- FL2003 %>%
mutate(lgdp = log(lgdpen))
head(FL2003)
FL2003$lgdp <- log(FL2003$gdpen)
#tidy
FL2003 <- FL2003 %>%
mutate(lgdp = log(gdpen))
head(FL2003)
attributes(FL2003)
attributes(FL2003)$var.labels
#tidy
FL2003 <- FL2003 %>%
mutate(random = rnorm(nrow(FL2003)),
random = NULL) ##Remove this variable
head(FL2003)
# Or select it out
FL2003 <- FL2003 %>%
mutate(random = rnorm(nrow(FL2003))) %>%
select(!random)##Remove this variable
head(FL2003)
?starts_with
FL2003 <-> mutate(demDummy = as.numeric(polity2 >= 7))
FL2003 <- FL2003 %>%
mutate(demDummy = as.numeric(polity2 >= 7))
View(FL2003)
summary(FL2003$demDummy)
## or with if and else
FL2003 <- FL2003 %>%
mutate(demDummy = ifelse(polity2 >= 7, 1,0))
summary(FL2003$demDummy)
FullData <- FL2003 %>%
mutate(cdummies = model.matrix(~factor(cname)))
colnames(FullData)[c(1:10, 55:80)] ##Take a look
cDummies <- model.matrix(~factor(cname) - 1, data=FL2003)
dim(cDummies)
FullData
FullData <- FL2003 %>%
mutate(cdummies = model.matrix(~factor(cname)-1))
head(FullData)
dim(FullData)
cDummies <- model.matrix(~factor(cname) - 1, data=FL2003)
dim(cDummies)
colnames(FullData)
FullData <- FL2003 %>%
mutate(model.matrix(~factor(cname)-1))
colnames(FullData)
FullData <- FL2003 %>%
pivot_wider(names_from = cname, values_from = 1,
names_prefix = "cname_", values_fill = 0)
FullData
colnames(FullData)[c(1:10, 55:80)] ##Take a look
FullData$cname_USA
FullData$cname_CANADA
FullData <- FL2003 %>%
mutate(const=1)
FullData$cname_CANADA
FullData <- FL2003 %>%
mutate(const=1) %>%
pivot_wider(names_from = cname, values_from = const,
names_prefix = "cname_", values_fill = 0)
FullData$cname_CANADA
FullData$cname_USA
cDummies <- model.matrix(~factor(cname) - 1, data=FL2003)
FullData <- cbind(FL2003, cDummies)
colnames(FullData)[c(1:10, 55:80)] ##Take a look
# Tidy solution: hack pivot wider
FullData <- FL2003 %>%
mutate(const=1) %>%
pivot_wider(names_from = cname, values_from = const,
names_prefix = "cname_", values_fill = 0)
colnames(FullData)[c(1:10, 55:80)] ##Take a look
FL2003 <- FL2003 %>%
group_by(ccode) %>%
arrange(year) %>%
mutate(LagOnset=lag(onset))
head(FL2003)
FL2003 <- FL2003 %>%
arrange(year) %>%
group_by(ccode) %>%
mutate(LagOnset=lag(onset))
head(FL2003)
FL2003 <- FL2003 %>%
arrange(ccode, year) %>%
group_by(ccode) %>%
mutate(LagOnset=lag(onset))
head(FL2003)
FL2003 %>%
filter(ccode==200) %>%
select(cname, year, onset, LagOnset)
FL2003 %>%
filter(ccode==200 & year > 1960) %>%
select(cname, year, onset, LagOnset)
FL2003 %>%
filter(ccode==200 & year > 1965) %>%
select(cname, year, onset, LagOnset) %>% head()
## Tidy approach
temp.dat <- FL2003 %>%
select(ccode, year)
head(temp.dat)
## DT approach
FL.dt <- data.table(FL2003) #need to convert first
sessionInfo()
2*
3
log(10)  #base= e
log(10, base=10)
exp(1)
sin(0)
acos(-1)
log(0)
log(-1)
x <- exp(1)
x = exp(1)
exp(1) -> x
assign('x', exp(1))
x
x-2
log(x)
x <- exp(2)
x
n <- 50 #Good but not descriptive
numberOfStates <- 50 #Good and descriptive
number.of.states <- 50 #Still good
number_of_states <- 50 #Still good
number-of-states <- 50 #Not good
2+2
x1 <- c(1, 2, 3, 4)
x1
x2 <- c(1, 0, -1, 1)
c(x2, x2, x2, x1, x1, x1, x2, x2, x1, x1)
x1+x2
x1/x2
log(x1)
sum(x1)
prod(x1)
mean(x1)
median(x1)
sd(x1)
sort(x1)
sort(x1, decreasing=TRUE)
length(x1)
1:15
5:2
seq(0, 20)
seq(0, 20, by=2)
seq(0, 20, length.out=5)
rep(10, 2)
rep(x1, 3)
rep(x1, each=3) #Repeats each number within x1 one at a time
z <- seq(0, 6, by =2)
z[3] #3rd entry
z[1:3] #1st three entries
z[c(1, 3)] #Entries 1 and 3, note that we need c()
z[-c(1,3)] #Everything but 1 and 3
z > 3
z[z>3]
z > 3 & z< 5
z[z > 3 & z < 5]
z[z < 3 | z > 5]
ls()
rm(list='number.of.states')
ls()
rm(list=c('x1', 'y2')) #We can delete more than one thing at time.
ls()
rm(list=ls()) #We can delete everything
ls()
x <- c('cat', 'dog', 'horse')
x <- 1:10
matrix(x, nrow=2)
matrix(x, ncol=2)
matrix(x, ncol=2, byrow=TRUE)
x2 <- -10:-1
cbind(x, x2)
rbind(x, x2)
z <- 1:5
cbind(x, x2, z)
diag(4) # 4 x 4 identity matrix
diag(x) #A square matrix with diagonal = x
Z <- matrix(1:9, nrow = 3)
Z
diag(Z) #Extract the diagonal of a square matrix
c(Z)
as.vector(Z)
class(x)
class(Z)
X <- matrix(1:12, nrow=3)
X
X[2, 4]
X[3,2]<-8
X
X[1, ]  #First row
X[, 2]  #Second Column
X[1:2,] ##First two columns
X[1, ,drop=FALSE]
class(X[1, ,drop=FALSE])
X[, 2] == 8 # which rows have 8 in the second column?
X[X[, 2] == 8, ]
length(X)
mean(X)
sd(X)
dim(X) #dimensions of X
nrow(X) #rows of X
ncol(X) #columns of X
mean.x <- rep(0, ncol(X)) #Recall that this creates a vector of 0s
#equal to the length of ncol(X)
for(i in 1:ncol(X)){
mean.x[i] <-  mean(X[,i])  #What does this do?
}
mean.x
apply(X, 2, mean) # Same thing
colMeans(X) #Best way to do this!
X <- diag(2)
colnames(X)
colnames(X) <- c('left', 'right')
X
colnames(X)[2] <- 'Right'
X
row.names(X) <- c('up', 'down')
X
X[,'left']  ## We can use the names in place of numbers to index
X['up', 'left']
X <-  matrix(1:4, nrow=2)
Y <- diag(2) #Identity matrix
X + Y
X-Y
X*Y
X %*% Y
c(1, 1) %*% X
X %*% c(1,1)
X
t(X)
A = matrix(1:6, nrow=2)
B = matrix(1:6, nrow=3)
A %*% B  #Matrix multiplication
solve(X)
solve(X) %*% X
set.seed(1)
Z <- matrix(rnorm(16), nrow = 4)
solve(Z) %*% Z
round(solve(Z) %*%Z, digits=12)
Y <- matrix(c(1, 0.5, 0.5, 1), nrow=2)
det(Y)
chol(Y)
t(chol(Y)) %*% chol(Y)  #make sure it worked
sum(diag(Y)) #trace
eigen(Y)
names(eigen(Y))
eigen(Y)$values
eigen(Y)$vectors
eigen(Y)[[2]]
class(eigen(Y)[[2]])
matrixList <- list(matrix = diag(4), #Identity matrix
M2 = Y,
Eig = eigen(Y))
matrixList
matrixList$Eig$vectors
matrixList[[3]][[2]] #Same thing
lapply(matrixList, class)
sapply(matrixList, class)
matrixList <- list(matrix1 = matrix(1:9, nrow=3), 	#3 x 3
matrix2 = matrix(0:5, nrow=2), 	#2 x 3
matrix3 = cbind(rnorm(3), 1))   	#3 x 2
matrixList
sapply(matrixList, class) # make sure they're all matrices
sapply(matrixList, dim)   # check dimensions
lapply(matrixList, apply, 2, mean)
X <- matrix(c(1, NA, 1,1), nrow=2) #Row 2 has a missing value
mean(X[2, ])  #is NA
mean(X[2, ], na.rm=TRUE) #Tells R to just ignore missing values
apply(X, 1, mean) #Gives us that NA
apply(X, 1, mean, na.rm=TRUE) #add option na.rm=TRUE
library(MASS)
y <- FALSE
if(y){
cat("Hello World")
}else{
cat("Goodbye")
}
test <- runif(1)
print(test)
if(test < 1/2){
if(test < 1/3){
"Mary"
}else{
if(test < 0.4){
"Frank"
}else{
"Liz"
}
}
}else{
"Bob"
}
test <- runif(10)
print(test)
ifelse(test < 1/2,
0,
1)
print(test)
ifelse(test < 1/2,
ifelse(test < 1/3,
"Mary",
ifelse(test < 0.4,
"Frank",
"Liz")),
"Bob")
y <- 1:10
for(i in 1:10){
y[i] <- y[i]^2
}
y
y <- 1:10
for(i in 1:10){
if(y[i] %% 2){
print("y is odd")
}else{
print("y is even")
}
}
repeat{
y <- runif(1)
if(y< .05){
break
}
}
y
#Create initial value of y that satifies the condition
y <- 1
while(y>0.05){
y <- runif(1)
}
y
X <- replicate(3, rnorm(10))
apply(X, 2, sd) #take the standard deviation of each column
apply(X, 1, max) #max of each row
apply(X, 1, function(x){ifelse(all(x>0), # can you explain this?
return(max(x)),
return(min(x)))})
X <- list(A = diag(1:4),
B = matrix(1:4, nrow=2))
lapply(X, solve)
lapply(X, t)
X <- list(A = diag(1:4),
B = matrix(1:4, nrow=2))
#Look at the difference between
sapply(X, max)
lapply(X, max)
getwd() ##Returns the current working directory
setwd('~/Dropbox/Rcourse_2021update') ##Change
getwd() ##Returns the new directory
source('test1.R', echo=TRUE)
ls()
X <- cbind(rnorm(1000), 1:1000)
apply(X, 2, summarize)
lapply( apply(X, 2, summarize), unlist)
Psi <- function(p){
pI <- pnorm(5*p[2]-2)
pC <- pnorm(5*p[1]-3)
return(c(pI,pC) -p)
}
jac <- function(p){
DpI <- c(-1, 5*dnorm(5*p[1]-3))
DpC <- c(5*dnorm(5*p[1]-2), -1)
return(cbind(DpI, DpC))
}
Newton <- function(func, jac, x0, tol=1e-5){
xold <- x0
diff <- 1
while(diff > tol){
xnew <- xold - func(xold)%*% solve(jac(xold))
diff <- max(abs(xnew-xold))
xold <- xnew
}
return(xnew)
}
x0 <- c(.5,.5)
p.eq <- Newton(func=Psi, jac=jac, x0=x0)
p.eq
set.seed(1)
N <- 2000
X <- cbind(1, replicate(2,rnorm(N)))
beta <- c(-1, 2, -2)
sigma2 <- 1
y <- X %*% beta + rnorm(N, 0, sqrt(sigma2))
NormalMLE <- function(theta, X, y){
eta <- theta[length(theta)] #extract eta from parameter vector
beta <- theta[-length(theta)] #beta coefficients
Lik <- - 1/2 * eta - 1/(2*exp(eta)) * (y - X%*%beta)^2 #L* from above
Lik <- -sum(Lik)
return(Lik)
}
grNormalMLE <- function(theta, X,y){
lnsigma2 <- theta[length(theta)] #extract eta from parameter vector
sigma2 <- exp(lnsigma2)
beta <- theta[-length(theta)] #beta coefficients
dBeta <- (X * as.numeric(y-X%*%beta))/sigma2
dln.sigma2 <- (y- X%*%beta)^2 / (2*sigma2) - 1/2
D <- colSums(cbind(dBeta, dln.sigma2))
return(-D)
}
#Should look something like this, but your results may
#differ based on the seed value.
grNormalMLE(rep(0,4), X=X, y=y)
##optim is a nonlinear optimizer that takes the following inputs
#par = starting values, in our case draws from the uniform.
#      These correspond to theta above
#fn = function to optimize
#gr = gradient (first derivatives)
#method = Method to use for optimization BFGS is a quasi-Newton method
#         that works really well on most problems
#X, y are the extra arguements that we included in the  NormalMLE
#     and grNormalMLE functions.
optim(par=runif(4), fn=NormalMLE, gr=grNormalMLE, method="BFGS", X=X, y=y)
mod1 <- optim(par=runif(4), fn=NormalMLE, method="BFGS", X=X, y=y,
gr=grNormalMLE, hessian=TRUE)
vcov1 <- solve(mod1$hessian)
sqrt(diag(vcov1))
library(MASS) #for the multivariate normal
N <- 2000 #Sample size
rho <- c(-0.5, 0, 0.5) #Values of rho
beta <- c(1, -2, 2) #True betas
MCresults <- list() #empty list
for(r in 1:3){ #loop over values of rho
results <- matrix(0, nrow=1000, ncol=2)
for(i in 1:1000){
Sigma <- matrix(c(1, rho[r], rho[r],1), nrow=2)
X <- mvrnorm(N, c(0,0), Sigma)
y <- cbind(1, X) %*% beta + rnorm(N)
X1 <- cbind(1, X[,1])
bhat <- solve(t(X1)%*%X1)%*%t(X1)%*%y
bias <- beta[-3] - bhat #what's the -3 do?
results[i,] <- bias
}
biasOut <- cbind(colMeans(results),
t(apply(results, 2, quantile,  #explain this?
c(0.025, 0.97)))) #and this?
MCresults[[r]] <- biasOut
}
names(MCresults) <- paste("rho:", rho)
MCresults <- lapply(MCresults,
function(x){
rownames(x) <- c("bias in hat(beta)[0]", "bias in hat(beta)[1]")
return(x)
}
)
MCresults
# Tidy packages
library(readr)
library(dplyr)
#Alternative
library(data.table)
# for stata files (i like it better than haven)
library(readstata13)
##Notice that I use relative paths below. You should use the setwd()
##command that we learned before to change your working directory to
##directory that contains the datasets folder **before** trying these examples
##ordinary csv
NMC <- read_csv('Datasets/NMC_Supplement_v4_0.csv')
##stata dataset
FL2003 <- read.dta13('Datasets/FearonLaitin_CivilWar2003.dta')
# A warning. Let's do what it says
FL2003 <- read.dta13('Datasets/FearonLaitin_CivilWar2003.dta',
nonint.factors=TRUE)
class(NMC)
class(FL2003)
head(FL2003) #Top  6
tail(FL2003) #Last 6
summary(FL2003[, 1:10]) ##Truncated the first 10 columns to save space
colnames(FL2003)
summary(FL2003$pop)
summary(FL2003[,18]) ##But isn't the dollar sign easier?
## Doing vector stuff with variables
FL2003$pop[1:10]
head(log(FL2003$pop))
##These all do the same thing
temp.dat <- FL2003[, c('ccode', 'year')]
head(temp.dat)
temp.dat <- FL2003[, c(53, 2)]
head(temp.dat)
temp.dat <- cbind.data.frame(FL2003$ccode, FL2003$year)
head(temp.dat)##notice this way messes up the column names
temp.dat <- with(FL2003, cbind.data.frame(ccode, year))
head(temp.dat)
temp.dat <- subset(FL2003, select=c('ccode', 'year'))
head(temp.dat)
## Tidy approach
temp.dat <- FL2003 %>%
select(ccode, year)
